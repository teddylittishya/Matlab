<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      -->
<title>Assignment9</title>
<meta name="generator" content="MATLAB 23.2">
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
<meta name="DC.date" content="2024-04-17">
<meta name="DC.source" content="Assignment9.m">
<style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style>
</head>
<body>
<div class="content">
<h2>Contents</h2>
<div>
<ul>
<li>
<a href="#1">SOLUTION 1</a>
</li>
<li>
<a href="#2">SOLUTION 2</a>
</li>
<li>
<a href="#3">EXPLANATION 3</a>
</li>
</ul>
</div>
<h2 id="1">SOLUTION 1</h2>
<pre class="codeinput">load(<span class="string">"usps_all.mat"</span>);

<span class="comment">% Merge the resulting 2000 entries into a single matrix of size 256 &times; 2000</span>
<span class="comment">%  that will be used as the train set.</span>
usps_train_class1 = double(data(:,1:1000,3)')./255;
usps_train_class2 = double(data(:,1:1000,8)')./255;

<span class="comment">% Merge the train set images into a single matrix</span>
<span class="comment">%Extract the remaining 100 images for each class</span>
usps_test_class1 = double(data(:,1001:1100,3)')./255;
usps_test_class2 = double(data(:,1001:1100,8)')./255;


<span class="comment">% Handpick ten pixels that are least relevant for classifying the data</span>
<span class="comment">% Here we choose the first ten pixels, assuming they are on the edge of the</span>
<span class="comment">%  image and thus contain less information for classification</span>
<span class="comment">% You should adjust this based on your own analysis</span>
least_relevant_pixels = 1:10;

<span class="comment">% Remove the least relevant pixels from the training and testing data</span>
<span class="comment">% Remove the least relevant pixels from the training and testing data</span>
usps_train_class1(:, least_relevant_pixels) = [];
usps_train_class2(:, least_relevant_pixels) = [];
usps_test_class1(:, least_relevant_pixels) = [];
usps_test_class2(:, least_relevant_pixels) = [];


<span class="comment">% Concatenate</span>
usps_train = cat(1, usps_train_class1, usps_train_class2)';
usps_test = cat(1, usps_test_class1, usps_test_class2)';

<span class="comment">% Set the number of samples</span>
samples_count = 1100;
class1_labels = zeros(samples_count, 1);
class2_labels = ones(samples_count, 1);

<span class="comment">% Concatenate training and test labels</span>
train_labels = cat(1, class1_labels(1:1000), class2_labels(1:1000));
test_labels = cat(1, class1_labels(1001:end), class2_labels(1001:end));

<span class="comment">% Fit a Soft SVM model to the data</span>
<span class="comment">% 'Standardize' is set to true to standardize the predictors</span>
<span class="comment">% 'KernelFunction' is set to 'linear' to use a linear kernel function</span>
<span class="comment">% 'KernelScale' is set to 'auto' to automatically scale the predictors</span>
<span class="comment">% 'BoxConstraint' is set to 1 for a soft-margin SVM</span>
svm_model = fitcsvm(usps_train', train_labels, <span class="string">'Standardize'</span>,true,<span class="string">'KernelFunction'</span>,<span class="string">'linear'</span>,<span class="string">'KernelScale'</span>,<span class="string">'auto'</span>,<span class="string">'BoxConstraint'</span>, 1);
svm_model = fitPosterior(svm_model, usps_train',train_labels);
[labels, posterior] = predict(svm_model, usps_test');
<span class="comment">% Count the number of mislabeled points</span>
mislabeled = sum(labels ~= test_labels);
disp([<span class="string">'Mislabeled Points: '</span>, num2str(mislabeled)]);
<span class="comment">% Calculate accuracy</span>
accuracy = sum(labels == test_labels) / length(test_labels) * 100;
disp([<span class="string">'Accuracy: '</span>, num2str(accuracy), <span class="string">'%'</span>]);
</pre>
<pre class="codeoutput">Mislabeled Points: 5
Accuracy: 97.5%
</pre>
<h2 id="2">SOLUTION 2</h2>
<p>Load the USPS dataset</p>
<pre class="codeinput">load(<span class="string">"usps_all.mat"</span>);

<span class="comment">% Normalize the data by dividing by 255 and split it into training and</span>
<span class="comment">% testing sets for two classes</span>
<span class="comment">% The first 1000 entries of each class are used for training</span>
usps_train_class1 = double(data(:,1:1000,3)')./255;
usps_train_class2 = double(data(:,1:1000,8)')./255;

<span class="comment">% The next 100 entries of each class are used for testing</span>
usps_test_class1 = double(data(:,1001:1100,3)')./255;
usps_test_class2 = double(data(:,1001:1100,8)')./255;

<span class="comment">% Concatenate the training data from both classes</span>
usps_train = cat(1, usps_train_class1, usps_train_class2)';
<span class="comment">% Concatenate the testing data from both classes</span>
usps_test = cat(1, usps_test_class1, usps_test_class2)';

<span class="comment">% Handpick fifty pixels that are most relevant for classifying the data</span>
<span class="comment">% Here we choose the 50 pixels in the center of the image, assuming they</span>
<span class="comment">% contain the most information for classification</span>
most_relevant_pixels = 104:153;

<span class="comment">% Keep only the most relevant pixels in the training and testing data</span>
usps_train = usps_train(most_relevant_pixels, :);
usps_test = usps_test(most_relevant_pixels, :);

<span class="comment">% Set the number of samples</span>
samples_count = 1100;
class1_labels = zeros(samples_count, 1);
class2_labels = ones(samples_count, 1);

<span class="comment">% Concatenate training and test labels</span>
train_labels = cat(1, class1_labels(1:1000), class2_labels(1:1000));
test_labels = cat(1, class1_labels(1001:end), class2_labels(1001:end));

<span class="comment">% Fit a Soft SVM model to the data</span>
<span class="comment">% 'Standardize' is set to true to standardize the predictors</span>
<span class="comment">% 'KernelFunction' is set to 'linear' to use a linear kernel function</span>
<span class="comment">% 'KernelScale' is set to 'auto' to automatically scale the predictors</span>
<span class="comment">% 'BoxConstraint' is set to 1 for a soft-margin SVM</span>
svm_model = fitcsvm(usps_train', train_labels, <span class="string">'Standardize'</span>,true,<span class="string">'KernelFunction'</span>,<span class="string">'linear'</span>,<span class="string">'KernelScale'</span>,<span class="string">'auto'</span>,<span class="string">'BoxConstraint'</span>, 1);
svm_model = fitPosterior(svm_model, usps_train',train_labels);
[labels, posterior] = predict(svm_model, usps_test');
<span class="comment">% Count the number of mislabeled points</span>
mislabeled = sum(labels ~= test_labels);
disp([<span class="string">'Mislabeled Points: '</span>, num2str(mislabeled)]);
<span class="comment">% Calculate accuracy</span>
accuracy = sum(labels == test_labels) / length(test_labels) * 100;
disp([<span class="string">'Accuracy: '</span>, num2str(accuracy), <span class="string">'%'</span>]);
</pre>
<pre class="codeoutput">Mislabeled Points: 24
Accuracy: 88%
</pre>
<h2 id="3">EXPLANATION 3</h2>
<p>The choice of pixels for classifying data can significantly impact the performance of the model. At first it is logically viable to use the set of pixels based on a manual analysis. However, it is important to remember that the relevance of a pixel (or any feature in a machine learning task)is context-dependent. A pixel that is highly informative for one task might be less informative for another. Therefore, it is always a good idea to perform some exploratory data analysis and feature selection process tailored to the specific task at hand.</p>
<pre>     - Manual selection can be beneficial when we have a good understanding
of the dataset and the problem at hand. It allows us to use our knowledge to
determine the most informative pixels, and it&rsquo;s easier to provide explanations
for our choice of pixels. However, this method becomes less effective when
there are more classes to classify, and it&rsquo;s not very scalable.</pre>
<pre>     - Eventhough 50 most relevant pixels contain important information
for classification, they don't capture all the information needed to achieve the highest accuracy.
The less relevant pixels, while individually not as informative, here collectively
contribute valuable information for classification.</pre>
<p>In terms of manual selection versus PCA, these results suggest that manual selection can be effective if you have a strong understanding of which features are most relevant. However, it also shows that this approach can miss important information contained in other features.</p>
<p>On the other hand, PCA or other dimensionality reduction techniques can help ensure that the most informative combination of features is used, potentially leading to better performance.</p>
<p>Pros and cons of manually selecting pixels versus employing an algorithm like PCA</p>
<pre>  Manual selection:</pre>
<pre>     - Pros: If we have a good understanding of the dataset and the problem at hand,
             we would be able to make educated guess about the features ie, pixels that are most relevant.
             It&rsquo;s a straightforward method that doesn&rsquo;t require any additional computational resources.
             Moreover, One advantage of selecting pixels by hand is that we may utilize our visual perception
             of the photos to pinpoint the locations of the most informative ones. This makes it simpler to
             justify our selections of pixels.</pre>
<pre>     - Cons: In terms of scalability, as the dimensiion of thedata increases, manually selecting features becomes
             increasingly impractical. For instance, here we chose the classes 3 and 8 and selected the most
             relevant pixels from the center of the images. But if we
             want to choose all the classes from 0 to 9, it becomes complicated.</pre>
<pre>   PCA:
     - Pros: PCA can help to reduce the dimensionality of data
             while retaining the most important information. PCA can reduce the dimensionality of the data
             while preserving as much variance as possible. This can help to speed up the training process and
             reduce the risk of overfitting.</pre>
<pre>             -&gt; PCA can automatically identify the most important features (in this case, pixels) in the dataset.
             This can be particularly useful when the data has many classes, making it more scalable than manual selection.</pre>
<pre>    - Cons: PCA can be sensitive to noise in the data. If some pixels have high variance due to noise rather than
            meaningful information, PCA might incorrectly identify these as important.</pre>
<pre>            -&gt; The principal components identified by PCA are linear combinations of the original features and can be hard
            to interpret. This can make it more difficult to explain the model&rsquo;s decisions than when features are
            manually selected.</pre>
<p class="footer">
<br>
<a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2023b</a>
<br>
</p>
</div>
<!--
##### SOURCE BEGIN #####
%% SOLUTION 1
load("usps_all.mat");

% Merge the resulting 2000 entries into a single matrix of size 256 × 2000
%  that will be used as the train set.
usps_train_class1 = double(data(:,1:1000,3)')./255;
usps_train_class2 = double(data(:,1:1000,8)')./255;

% Merge the train set images into a single matrix
%Extract the remaining 100 images for each class
usps_test_class1 = double(data(:,1001:1100,3)')./255;
usps_test_class2 = double(data(:,1001:1100,8)')./255;


% Handpick ten pixels that are least relevant for classifying the data
% Here we choose the first ten pixels, assuming they are on the edge of the
%  image and thus contain less information for classification
% You should adjust this based on your own analysis
least_relevant_pixels = 1:10;

% Remove the least relevant pixels from the training and testing data
% Remove the least relevant pixels from the training and testing data
usps_train_class1(:, least_relevant_pixels) = [];
usps_train_class2(:, least_relevant_pixels) = [];
usps_test_class1(:, least_relevant_pixels) = [];
usps_test_class2(:, least_relevant_pixels) = [];


% Concatenate
usps_train = cat(1, usps_train_class1, usps_train_class2)';
usps_test = cat(1, usps_test_class1, usps_test_class2)';

% Set the number of samples
samples_count = 1100;
class1_labels = zeros(samples_count, 1);
class2_labels = ones(samples_count, 1);

% Concatenate training and test labels
train_labels = cat(1, class1_labels(1:1000), class2_labels(1:1000));
test_labels = cat(1, class1_labels(1001:end), class2_labels(1001:end));

% Fit a Soft SVM model to the data
% 'Standardize' is set to true to standardize the predictors
% 'KernelFunction' is set to 'linear' to use a linear kernel function
% 'KernelScale' is set to 'auto' to automatically scale the predictors
% 'BoxConstraint' is set to 1 for a soft-margin SVM
svm_model = fitcsvm(usps_train', train_labels, 'Standardize',true,'KernelFunction','linear','KernelScale','auto','BoxConstraint', 1);
svm_model = fitPosterior(svm_model, usps_train',train_labels);
[labels, posterior] = predict(svm_model, usps_test');
% Count the number of mislabeled points
mislabeled = sum(labels ~= test_labels);
disp(['Mislabeled Points: ', num2str(mislabeled)]);
% Calculate accuracy
accuracy = sum(labels == test_labels) / length(test_labels) * 100;
disp(['Accuracy: ', num2str(accuracy), '%']);

%% SOLUTION 2
% Load the USPS dataset
load("usps_all.mat");

% Normalize the data by dividing by 255 and split it into training and 
% testing sets for two classes
% The first 1000 entries of each class are used for training
usps_train_class1 = double(data(:,1:1000,3)')./255;
usps_train_class2 = double(data(:,1:1000,8)')./255;

% The next 100 entries of each class are used for testing
usps_test_class1 = double(data(:,1001:1100,3)')./255;
usps_test_class2 = double(data(:,1001:1100,8)')./255;

% Concatenate the training data from both classes
usps_train = cat(1, usps_train_class1, usps_train_class2)';
% Concatenate the testing data from both classes
usps_test = cat(1, usps_test_class1, usps_test_class2)';

% Handpick fifty pixels that are most relevant for classifying the data
% Here we choose the 50 pixels in the center of the image, assuming they 
% contain the most information for classification
most_relevant_pixels = 104:153;

% Keep only the most relevant pixels in the training and testing data
usps_train = usps_train(most_relevant_pixels, :);
usps_test = usps_test(most_relevant_pixels, :);

% Set the number of samples
samples_count = 1100;
class1_labels = zeros(samples_count, 1);
class2_labels = ones(samples_count, 1);

% Concatenate training and test labels
train_labels = cat(1, class1_labels(1:1000), class2_labels(1:1000));
test_labels = cat(1, class1_labels(1001:end), class2_labels(1001:end));

% Fit a Soft SVM model to the data
% 'Standardize' is set to true to standardize the predictors
% 'KernelFunction' is set to 'linear' to use a linear kernel function
% 'KernelScale' is set to 'auto' to automatically scale the predictors
% 'BoxConstraint' is set to 1 for a soft-margin SVM
svm_model = fitcsvm(usps_train', train_labels, 'Standardize',true,'KernelFunction','linear','KernelScale','auto','BoxConstraint', 1);
svm_model = fitPosterior(svm_model, usps_train',train_labels);
[labels, posterior] = predict(svm_model, usps_test');
% Count the number of mislabeled points
mislabeled = sum(labels ~= test_labels);
disp(['Mislabeled Points: ', num2str(mislabeled)]);
% Calculate accuracy
accuracy = sum(labels == test_labels) / length(test_labels) * 100;
disp(['Accuracy: ', num2str(accuracy), '%']);

%% EXPLANATION 3
% The choice of pixels for classifying data can significantly impact the
% performance of the model. At first it is logically viable to use the 
% set of pixels based on a manual analysis. However, it is important to 
% remember that the relevance of a pixel (or any feature in a machine 
% learning task)is context-dependent. A pixel that is highly informative
%  for one task might be less informative for another.
% Therefore, it is always a good idea to perform some exploratory data analysis 
% and feature selection process tailored to the specific task at hand.
%       
%       - Manual selection can be beneficial when we have a good understanding 
% of the dataset and the problem at hand. It allows us to use our knowledge to
%  determine the most informative pixels, and it’s easier to provide explanations
%  for our choice of pixels. However, this method becomes less effective when
%  there are more classes to classify, and it’s not very scalable.
%  
%       - Eventhough 50 most relevant pixels contain important information
%  for classification, they don't capture all the information needed to achieve the highest accuracy.
% The less relevant pixels, while individually not as informative, here collectively 
% contribute valuable information for classification.
% 
% In terms of manual selection versus PCA, these results suggest that manual selection
% can be effective if you have a strong understanding of which features are most relevant.
% However, it also shows that this approach can miss important information contained 
% in other features. 
% 
% On the other hand, PCA or other dimensionality reduction techniques can help ensure 
% that the most informative combination of features is used, potentially leading to better performance.
% 
% Pros and cons of manually selecting pixels versus employing an algorithm
% like PCA
%
%    Manual selection: 
%
%       - Pros: If we have a good understanding of the dataset and the problem at hand, 
%               we would be able to make educated guess about the features ie, pixels that are most relevant. 
%               It’s a straightforward method that doesn’t require any additional computational resources.
%               Moreover, One advantage of selecting pixels by hand is that we may utilize our visual perception
%               of the photos to pinpoint the locations of the most informative ones. This makes it simpler to 
%               justify our selections of pixels.  
%
%       - Cons: In terms of scalability, as the dimensiion of thedata increases, manually selecting features becomes
%               increasingly impractical. For instance, here we chose the classes 3 and 8 and selected the most
%               relevant pixels from the center of the images. But if we
%               want to choose all the classes from 0 to 9, it becomes complicated.
%                
%     PCA: 
%       - Pros: PCA can help to reduce the dimensionality of data
%               while retaining the most important information. PCA can reduce the dimensionality of the data 
%               while preserving as much variance as possible. This can help to speed up the training process and 
%               reduce the risk of overfitting. 
%
%               -> PCA can automatically identify the most important features (in this case, pixels) in the dataset.
%               This can be particularly useful when the data has many classes, making it more scalable than manual selection.
%                
%      - Cons: PCA can be sensitive to noise in the data. If some pixels have high variance due to noise rather than 
%              meaningful information, PCA might incorrectly identify these as important.
%              
%              -> The principal components identified by PCA are linear combinations of the original features and can be hard
%              to interpret. This can make it more difficult to explain the model’s decisions than when features are
%              manually selected.
%
%                       

##### SOURCE END #####
-->
</body>
</html>
