<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      -->
<title>Assignment7</title>
<meta name="generator" content="MATLAB 23.2">
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
<meta name="DC.date" content="2024-03-31">
<meta name="DC.source" content="Assignment7.m">
<style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style>
</head>
<body>
<div class="content">
<pre class="codeinput">
<span class="comment">% Import the USPS dataset</span>
load(<span class="string">'usps_all.mat'</span>)

<span class="comment">% Initialize cell arrays to store images of each digit for different data sets</span>
<span class="comment">% Each cell array will contain 10 cells, one for each digit (0-9)</span>
digit_training_images = cell(1, 10);   <span class="comment">% For training data</span>
digit_validation_images = cell(1, 10); <span class="comment">% For validation data</span>
digit_testing_images = cell(1, 10);    <span class="comment">% For testing data</span>

<span class="comment">% Initialize arrays to hold the corresponding labels for each image in the data sets</span>
<span class="comment">% These labels will be used to train and evaluate the model</span>
training_labels = [];   <span class="comment">% Labels for training data</span>
validation_labels = []; <span class="comment">% Labels for validation data</span>
testing_labels = [];    <span class="comment">% Labels for testing data</span>

<span class="comment">% Divide the data into training, validation, and testing sets for each digit</span>
<span class="keyword">for</span> digit = 1:10
    <span class="comment">% Extract 800 images for training</span>
    training_images = data(:, 1:800, digit);
    <span class="comment">% Extract 200 images for validation</span>
    validation_images = data(:, 801:1000, digit);
    <span class="comment">% Extract 100 images for testing</span>
    testing_images = data(:, 1001:1100, digit);

    <span class="comment">% Save the images in the corresponding cell arrays</span>
    digit_training_images{digit} = training_images;
    digit_validation_images{digit} = validation_images;
    digit_testing_images{digit} = testing_images;

    <span class="comment">% Generate labels for training, validation, and testing</span>
    train_labels = repmat(digit, 1, 800);
    training_labels = [training_labels, train_labels];

    validation_labels = [validation_labels, repmat(digit, 1, 200)];
    testing_labels = [testing_labels, repmat(digit, 1, 100)];
<span class="keyword">end</span>

<span class="comment">% Merge the data for training, validation, and testing</span>
concatenated_training_data = cat(2, digit_training_images{:});
concatenated_validation_data = cat(2, digit_validation_images{:});
concatenated_testing_data = cat(2, digit_testing_images{:});

<span class="comment">% Rearrange labels</span>
training_labels = transpose(training_labels);
validation_labels = transpose(validation_labels);
testing_labels = transpose(testing_labels);

<span class="comment">% Rearrange data</span>
concatenated_training_data = transpose(double(concatenated_training_data));
concatenated_validation_data = transpose(double(concatenated_validation_data));
concatenated_testing_data = transpose(double(concatenated_testing_data));

<span class="comment">% Execute k-NN classification with varying numbers of neighbors</span>
<span class="keyword">for</span> k = 1:20
    knn_model = fitcknn(concatenated_training_data, training_labels, <span class="string">'NumNeighbors'</span>, k, <span class="string">'Distance'</span>, <span class="string">'euclidean'</span>);
    predictions = predict(knn_model, concatenated_validation_data);
    accuracy = sum(predictions == validation_labels) / numel(validation_labels);
    disp([<span class="string">'Accuracy for '</span>, num2str(k), <span class="string">' neighbors: '</span>, num2str(accuracy)]);
<span class="keyword">end</span>

<span class="comment">% Finalize k-NN model with 3 neighbors for testing</span>
final_knn_model = fitcknn(concatenated_training_data, training_labels, <span class="string">'NumNeighbors'</span>, 3, <span class="string">'Distance'</span>, <span class="string">'euclidean'</span>);
test_predictions = predict(final_knn_model, concatenated_testing_data);
test_accuracy = sum(test_predictions == testing_labels) / numel(testing_labels);
disp([<span class="string">'Accuracy for the test set: '</span>, num2str(test_accuracy)]);

<span class="comment">% Calculate error rates for validation and testing sets</span>
validation_error_rate = 1 - 0.9505;
testing_error_rate = 1 - 0.945;
disp([<span class="string">'Error rate of the validation set: '</span>, num2str(validation_error_rate)]);
disp([<span class="string">'Error rate of the testing set: '</span>, num2str(testing_error_rate)]);
<span class="comment">% When k=1 , it was overfitting , so I used k =3 which give sbetter</span>
<span class="comment">% accuracy</span>
<span class="comment">% The validation error rate is commonly lower than the testing error rate due to hyperparameter tuning on the validation set.</span>
<span class="comment">% Comparing the error rates obtained on the validation set (0.0495) and the testing set (0.055)</span>
<span class="comment">% Upon the analysis I got thge error rate on the testing set (0.055) is slightly higher than the error rate on the validation set (0.0495).</span>
<span class="comment">% Also the performance of the model slightly degraded when evaluated on the unseen testing data compared to the validation data.</span>
<span class="comment">% Despite the slight degradation in performance in the unseen test data, the model still demonstrates good generalization ability, with an accuracy of 0.945 on the testing set.</span>
</pre>
<pre class="codeoutput">Accuracy for 1 neighbors: 0.9505
Accuracy for 2 neighbors: 0.935
Accuracy for 3 neighbors: 0.9425
Accuracy for 4 neighbors: 0.94
Accuracy for 5 neighbors: 0.937
Accuracy for 6 neighbors: 0.9375
Accuracy for 7 neighbors: 0.937
Accuracy for 8 neighbors: 0.935
Accuracy for 9 neighbors: 0.936
Accuracy for 10 neighbors: 0.935
Accuracy for 11 neighbors: 0.933
Accuracy for 12 neighbors: 0.932
Accuracy for 13 neighbors: 0.9305
Accuracy for 14 neighbors: 0.927
Accuracy for 15 neighbors: 0.926
Accuracy for 16 neighbors: 0.924
Accuracy for 17 neighbors: 0.9235
Accuracy for 18 neighbors: 0.9245
Accuracy for 19 neighbors: 0.9245
Accuracy for 20 neighbors: 0.924
Accuracy for the test set: 0.942
Error rate of the validation set: 0.0495
Error rate of the testing set: 0.055
</pre>
<p>2. Precision = Sensitivity = False Omission Rate = Specificity = 80% For a binary classification experiment with 100 individuals (TP + TN + FP + FN), we have: Precision = TP / (TP + FP) Sensitivity = TP / (TP + FN) False Omission Rate = FN / (FN + TN) Specificity = TN / (FP + TN) Given that Precision, Sensitivity, False Omission Rate, and Specificity are all equal to 80%, let's denote this value as 0.80. From the precision equation: TP / (TP + FP) = 0.80 From the sensitivity equation: TP / (TP + FN) = 0.80 From the false omission rate equation: FN / (FN + TN) = 0.80 From the specificity equation: TN / (FP + TN) = 0.80 Now, let's solve these equations to find the values of TP, FP, FN, and TN.</p>
<p>From the precision equation: TP = 0.80(TP + FP) TP - 0.80TP = 0.80FP 0.20TP = 0.80FP TP = 4FP</p>
<p>From the sensitivity equation: TP = 0.80(TP + FN) TP - 0.80TP = 0.80FN 0.20TP = 0.80FN TP = 4FN</p>
<p>From the false omission rate equation: FN = 0.80(FN + TN) FN - 0.80FN = 0.80TN 0.20FN = 0.80TN FN = 4TN</p>
<p>From the specificity equation: TN = 0.80(FP + TN) TN - 0.80TN = 0.80FP 0.20TN = 0.80FP TN = 4FP</p>
<p>We can see that these equations result in a contradiction. It's not possible for TP, FP, FN, and TN to satisfy all conditions simultaneously. Therefore, such an experiment cannot be constructed. The given conditions are mathematically inconsistent. Hence, it's impossible to calculate the accuracy of this experiment.</p>
<p class="footer">
<br>
<a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2023b</a>
<br>
</p>
</div>
<!--
##### SOURCE BEGIN #####
% Import the USPS dataset
load('usps_all.mat')

% Initialize cell arrays to store images of each digit for different data sets
% Each cell array will contain 10 cells, one for each digit (0-9)
digit_training_images = cell(1, 10);   % For training data
digit_validation_images = cell(1, 10); % For validation data
digit_testing_images = cell(1, 10);    % For testing data

% Initialize arrays to hold the corresponding labels for each image in the data sets
% These labels will be used to train and evaluate the model
training_labels = [];   % Labels for training data
validation_labels = []; % Labels for validation data
testing_labels = [];    % Labels for testing data

% Divide the data into training, validation, and testing sets for each digit
for digit = 1:10
    % Extract 800 images for training
    training_images = data(:, 1:800, digit);
    % Extract 200 images for validation
    validation_images = data(:, 801:1000, digit);
    % Extract 100 images for testing
    testing_images = data(:, 1001:1100, digit);
    
    % Save the images in the corresponding cell arrays
    digit_training_images{digit} = training_images;
    digit_validation_images{digit} = validation_images;
    digit_testing_images{digit} = testing_images;
    
    % Generate labels for training, validation, and testing
    train_labels = repmat(digit, 1, 800);
    training_labels = [training_labels, train_labels];
    
    validation_labels = [validation_labels, repmat(digit, 1, 200)];
    testing_labels = [testing_labels, repmat(digit, 1, 100)];
end

% Merge the data for training, validation, and testing
concatenated_training_data = cat(2, digit_training_images{:});
concatenated_validation_data = cat(2, digit_validation_images{:});
concatenated_testing_data = cat(2, digit_testing_images{:});

% Rearrange labels
training_labels = transpose(training_labels);
validation_labels = transpose(validation_labels);
testing_labels = transpose(testing_labels);

% Rearrange data
concatenated_training_data = transpose(double(concatenated_training_data));
concatenated_validation_data = transpose(double(concatenated_validation_data));
concatenated_testing_data = transpose(double(concatenated_testing_data));

% Execute k-NN classification with varying numbers of neighbors
for k = 1:20
    knn_model = fitcknn(concatenated_training_data, training_labels, 'NumNeighbors', k, 'Distance', 'euclidean');
    predictions = predict(knn_model, concatenated_validation_data);
    accuracy = sum(predictions == validation_labels) / numel(validation_labels);
    disp(['Accuracy for ', num2str(k), ' neighbors: ', num2str(accuracy)]);
end

% Finalize k-NN model with 3 neighbors for testing
final_knn_model = fitcknn(concatenated_training_data, training_labels, 'NumNeighbors', 3, 'Distance', 'euclidean');
test_predictions = predict(final_knn_model, concatenated_testing_data);
test_accuracy = sum(test_predictions == testing_labels) / numel(testing_labels);
disp(['Accuracy for the test set: ', num2str(test_accuracy)]);

% Calculate error rates for validation and testing sets
validation_error_rate = 1 - 0.9505;
testing_error_rate = 1 - 0.945;
disp(['Error rate of the validation set: ', num2str(validation_error_rate)]);
disp(['Error rate of the testing set: ', num2str(testing_error_rate)]);
% When k=1 , it was overfitting , so I used k =3 which give sbetter
% accuracy
% The validation error rate is commonly lower than the testing error rate due to hyperparameter tuning on the validation set.
% Comparing the error rates obtained on the validation set (0.0495) and the testing set (0.055)
% Upon the analysis I got thge error rate on the testing set (0.055) is slightly higher than the error rate on the validation set (0.0495).
% Also the performance of the model slightly degraded when evaluated on the unseen testing data compared to the validation data.
% Despite the slight degradation in performance in the unseen test data, the model still demonstrates good generalization ability, with an accuracy of 0.945 on the testing set.

%%
% 2. 
% Precision = Sensitivity = False Omission Rate = Specificity = 80%
% For a binary classification experiment with 100 individuals (TP + TN + FP + FN), we have:
% Precision = TP / (TP + FP)
% Sensitivity = TP / (TP + FN)
% False Omission Rate = FN / (FN + TN)
% Specificity = TN / (FP + TN)
% Given that Precision, Sensitivity, False Omission Rate, and Specificity are all equal to 80%, let's denote this value as 0.80.
% From the precision equation: TP / (TP + FP) = 0.80
% From the sensitivity equation: TP / (TP + FN) = 0.80
% From the false omission rate equation: FN / (FN + TN) = 0.80
% From the specificity equation: TN / (FP + TN) = 0.80
% Now, let's solve these equations to find the values of TP, FP, FN, and TN.
% 
% From the precision equation: TP = 0.80(TP + FP)
% TP - 0.80TP = 0.80FP
% 0.20TP = 0.80FP
% TP = 4FP
% 
% From the sensitivity equation: TP = 0.80(TP + FN)
% TP - 0.80TP = 0.80FN
% 0.20TP = 0.80FN
% TP = 4FN
% 
% From the false omission rate equation: FN = 0.80(FN + TN)
% FN - 0.80FN = 0.80TN
% 0.20FN = 0.80TN
% FN = 4TN
% 
% From the specificity equation: TN = 0.80(FP + TN)
% TN - 0.80TN = 0.80FP
% 0.20TN = 0.80FP
% TN = 4FP
% 
% We can see that these equations result in a contradiction. It's not possible for TP, FP, FN, and TN to satisfy all conditions simultaneously.
% Therefore, such an experiment cannot be constructed. The given conditions are mathematically inconsistent. Hence, it's impossible to calculate the accuracy of this experiment.
% 

##### SOURCE END #####
-->
</body>
</html>
